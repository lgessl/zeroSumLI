\documentclass{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks,linkcolor=black,citecolor=black]{hyperref}
\usepackage[sort&compress,numbers]{natbib}
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}

%\VignetteEngine{knitr::knitr} 
%\VignetteIndexEntry{Algorithms for direct observation recording}

\author{T. Rehberg, M. Altenbuchinger}
\title{ZeroSum Vignette}

\begin{document}
\maketitle

\section{Introduction}
 \textit{zeroSum} is an R package for fitting reference point insensitive linear models. The coefficients 
 are penalized by the elastic net regularization \cite{ELASTICNET} and by the zero-sum constraint.
 The zero-sum constraint imposes that the sum over the regression weights vanishes. This constraint is 
 recommended for log-transformed data where ambiguities in the reference point translate to sample-wise 
 shifts. This approach has been proposed in the context of compositional data in \cite{Lin13082014} and in the 
 context of reference points in [\textcolor{red}{manuscript submitted}]. The corresponding minimization problem reads:
\begin{align*}
      \underset{ (\beta_0,\beta)\in\mathbb{R}^{p+1}}{\operatorname{min}} \Bigg[
       \frac{1}{2N} & \sum_{i=1}^n  \big(  y_{i}-\beta_0
       -\sum_{j=1}^p \beta_{j} x_{ij}    \big)^2   
      +\lambda \left( \frac{1-\alpha}{2} || \beta ||^2_2
      + \alpha ||\beta||_1 \right) \Bigg]\\ \nonumber
      &\text{subject to: }\quad \sum_j^p\beta_j = 0      \,.
\end{align*}
The parameter $\alpha$ can be used to adjust the ratio between ridge and LASSO regularization. 
For alpha = 0 the elastic net becomes
a ridge regularization, for alpha = 1  the elastic net becomes
the LASSO regularization.\\
The function calls of the \textit{zeroSum} package follow closely 
those of the \textit{glmnet} package \cite{GLMNET}. Therefore, the results of the linear models
with or without the zero-sum constraint can be easily compared.


\section{Quick start}
\subsection{Installation from github (Method 1)}
For an easy installation from github one can use the \textit{devtools} package, which can be installed by:

<<devtools, echo=TRUE, eval=FALSE>>==
install.packages("devtools")
@

After loading the \textit{devtools} package, the \textit{zeroSum} package can be installed directly
from github as follows:

<<install, echo=TRUE, eval=FALSE>>==
library("devtools")
install_github("rehbergT/zeroSum/zeroSum")
@


\subsection{Installation from source  (Method 2)}
Download the zeroSum\_0.8.0.tar.gz file from \url{https.github.com} for Linux or OS X. 
For Windows please download the binaries zeroSum\_0.8.0.tar.zip file from \url{https.github.com}
Use the following command on Linux or OS X to install the package:
\begin{quote}
R CMD INSTALL ZeroSumElasticNet\_0.80.0.tar.gz
\end{quote}
or the following on Windows
\begin{quote}
R CMD INSTALL ZeroSumElasticNet\_0.80.0.zip
\end{quote}




\subsection{Basic Workflow}


A dataset with 50 samples and 135 features can be simulated with the function \textit{simulateData()}:

<<loading, echo=TRUE, eval=TRUE, results='asis'>>=
library(zeroSum)

set.seed(1)
X <- log2(exampleData$x+1)
print(dim(X))

Y <- exampleData$y
print(length(Y))

@

By using the \textit{zeroSumCVFit()} function a $\lambda$-path is estimated and 
each value of $\lambda$ tested in cross validation. In this case we use the LASSO 
regularization with $\alpha=1$:

<<cvfit, echo=TRUE, eval=TRUE>>=
cv.fit <- zeroSumCVFit( X, Y, alpha=1)
@

One can plot the CV Error vs. $\lambda$ by using the \textit{plot} function: 

<<plot, echo=TRUE, eval=TRUE>>=
plot( cv.fit, main="CV-Fit" )
@

\textit{coef()} returns the coefficients of the fitted model. One can choose
between two different $lambda$ values: 
(1) $\lambda$="lambda.min" which 
returns the model corresponding to the smallest CV error. 
(2) $\lambda$="lambda.1SE", which is defined in accordance with the
\textit{glmnet} package \cite{GLMNET} as the $\lambda$ which gives the most
regularized model such that the CV error is within one standard error of the minimum.

<<coef, echo=TRUE, eval=TRUE>>=
 coefs <- coef( cv.fit, s="lambda.min" )
 head(coefs)
@

\subsection{Adjusting the $\lambda$-sequence}
We have implemented the following options to modify the $\lambda$ path tested in a \textit{zeroSumCVFit}:
\begin{itemize}
    \item \textbf{epsilon}: 
		for estimating the $\lambda$ sequence, an initial lambda value $\lambda_{\text{max}}$
		is determined such that all coefficients become zero, i.e. $\lambda_{\text{max}}$ is the upper
		bound of the lambda sequence. The lower bound is calculated by 
		$\lambda_{\text{min}} = \lambda_{\text{max}} \cdot \operatorname{epsilon}$. 
		The later parameter $\operatorname{epsilon}$ can be adjusted by this option.
  
                  
    \item \textbf{lambdaSteps}: 
		    this parameters determines the number of lambda steps evaluated between
		    $\lambda_{\text{min}}$ and $\lambda_{\text{max}}$, i.e. higher values for lambdaSteps improve 
		    the resolution of the regularization path.

    \item \textbf{cvStop}: This parameter stops the CV progress if the model's CV-error becomes successively
		worse for lower lambda values. The number of steps that are accepted before the CV routine 
		cancels is given by lambdaSteps (Default: 100) times cvStop (Default: 0.1). 
		Use cvStop = 0 or FALSE to deactivate the cvStop.
\end{itemize}


\bibliographystyle{unsrtnat}
\bibliography{cite}

\end{document}
